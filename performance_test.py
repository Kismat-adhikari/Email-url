#!/usr/bin/env python3
"""
Performance Test Script for Email Validator
Tests the optimized batch validation with 5000 emails
"""

import time
import json
import csv
import requests
from datetime import datetime
import statistics

def load_emails_from_csv(filename):
    """Load emails from CSV file."""
    emails = []
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            for row in reader:
                email = row.get('email', '').strip()
                if email:
                    emails.append(email)
        print(f"âœ… Loaded {len(emails)} emails from {filename}")
        return emails
    except Exception as e:
        print(f"âŒ Error loading CSV: {e}")
        return []

def test_batch_validation(emails, mode='advanced'):
    """Test batch validation performance."""
    print(f"\nðŸš€ Starting batch validation test...")
    print(f"ðŸ“Š Mode: {mode.upper()}")
    print(f"ðŸ“§ Emails: {len(emails)}")
    print(f"â° Start time: {datetime.now().strftime('%H:%M:%S')}")
    
    # Prepare request data
    url = "http://localhost:5000/api/validate/batch/local"
    headers = {
        'Content-Type': 'application/json',
        'X-User-ID': 'test-performance-user-12345'
    }
    data = {
        'emails': emails,
        'advanced': mode == 'advanced',
        'remove_duplicates': True
    }
    
    # Start timing
    start_time = time.time()
    
    try:
        # Send request
        print(f"ðŸ“¤ Sending request to {url}")
        response = requests.post(url, headers=headers, json=data, stream=True)
        
        if response.status_code != 200:
            print(f"âŒ Request failed: {response.status_code}")
            print(f"Response: {response.text}")
            return None
        
        # Process streaming response
        results = []
        progress_updates = []
        
        print(f"ðŸ“¥ Processing streaming response...")
        
        for line in response.iter_lines():
            if line:
                line_str = line.decode('utf-8')
                if line_str.startswith('data: '):
                    try:
                        data_json = json.loads(line_str[6:])
                        
                        if data_json.get('type') == 'start':
                            print(f"ðŸŽ¬ Validation started - Total: {data_json.get('total')}")
                        
                        elif data_json.get('type') == 'result':
                            result = data_json.get('result')
                            progress = data_json.get('progress')
                            
                            if result:
                                results.append(result)
                            
                            if progress:
                                progress_updates.append({
                                    'current': progress.get('current'),
                                    'total': progress.get('total'),
                                    'percentage': progress.get('percentage'),
                                    'valid': progress.get('valid'),
                                    'invalid': progress.get('invalid'),
                                    'timestamp': time.time() - start_time
                                })
                                
                                # Print progress every 100 emails
                                if progress.get('current', 0) % 100 == 0:
                                    elapsed = time.time() - start_time
                                    current = progress.get('current', 0)
                                    total = progress.get('total', 1)
                                    rate = current / elapsed if elapsed > 0 else 0
                                    eta = (total - current) / rate if rate > 0 else 0
                                    
                                    print(f"â³ Progress: {current}/{total} ({progress.get('percentage', 0)}%) "
                                          f"- Rate: {rate:.1f}/sec - ETA: {eta:.0f}s")
                        
                        elif data_json.get('type') == 'complete':
                            print(f"âœ… Validation completed!")
                            break
                            
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ JSON decode error: {e}")
                        continue
        
        # Calculate final timing
        end_time = time.time()
        total_time = end_time - start_time
        
        print(f"ðŸ Validation finished!")
        print(f"â° Total time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)")
        
        return {
            'results': results,
            'progress_updates': progress_updates,
            'total_time': total_time,
            'start_time': start_time,
            'end_time': end_time
        }
        
    except Exception as e:
        print(f"âŒ Error during validation: {e}")
        return None

def analyze_results(test_data, emails):
    """Analyze test results and generate report."""
    if not test_data:
        return None
    
    results = test_data['results']
    progress_updates = test_data['progress_updates']
    total_time = test_data['total_time']
    
    # Basic statistics
    total_emails = len(emails)
    processed_emails = len(results)
    valid_count = sum(1 for r in results if r.get('valid'))
    invalid_count = processed_emails - valid_count
    
    # Performance metrics
    emails_per_second = processed_emails / total_time if total_time > 0 else 0
    seconds_per_email = total_time / processed_emails if processed_emails > 0 else 0
    
    # Progress analysis
    if progress_updates:
        timestamps = [p['timestamp'] for p in progress_updates]
        rates = []
        for i in range(1, len(progress_updates)):
            time_diff = timestamps[i] - timestamps[i-1]
            email_diff = progress_updates[i]['current'] - progress_updates[i-1]['current']
            if time_diff > 0:
                rates.append(email_diff / time_diff)
        
        avg_rate = statistics.mean(rates) if rates else 0
        min_rate = min(rates) if rates else 0
        max_rate = max(rates) if rates else 0
    else:
        avg_rate = min_rate = max_rate = 0
    
    # Domain analysis
    domains = {}
    for result in results:
        email = result.get('email', '')
        if '@' in email:
            domain = email.split('@')[1].lower()
            if domain not in domains:
                domains[domain] = {'total': 0, 'valid': 0}
            domains[domain]['total'] += 1
            if result.get('valid'):
                domains[domain]['valid'] += 1
    
    # Top domains
    top_domains = sorted(domains.items(), key=lambda x: x[1]['total'], reverse=True)[:10]
    
    return {
        'summary': {
            'total_emails': total_emails,
            'processed_emails': processed_emails,
            'valid_count': valid_count,
            'invalid_count': invalid_count,
            'success_rate': (processed_emails / total_emails * 100) if total_emails > 0 else 0,
            'validity_rate': (valid_count / processed_emails * 100) if processed_emails > 0 else 0
        },
        'performance': {
            'total_time_seconds': total_time,
            'total_time_minutes': total_time / 60,
            'emails_per_second': emails_per_second,
            'seconds_per_email': seconds_per_email,
            'avg_rate': avg_rate,
            'min_rate': min_rate,
            'max_rate': max_rate
        },
        'domains': {
            'unique_domains': len(domains),
            'top_domains': top_domains
        },
        'progress_updates': len(progress_updates)
    }

def generate_report(analysis, mode):
    """Generate a detailed performance report."""
    if not analysis:
        return "âŒ No analysis data available"
    
    report = f"""
================================================================================
EMAIL VALIDATOR PERFORMANCE TEST REPORT
================================================================================

Test Configuration:
------------------
ðŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ðŸ”§ Mode: {mode.upper()}
ðŸŒ Endpoint: /api/validate/batch/local
âš¡ Optimizations: Parallel Processing + DNS Caching + Batch DB Writes

Results Summary:
---------------
ðŸ“§ Total Emails: {analysis['summary']['total_emails']:,}
âœ… Processed: {analysis['summary']['processed_emails']:,}
âœ… Valid: {analysis['summary']['valid_count']:,}
âŒ Invalid: {analysis['summary']['invalid_count']:,}
ðŸ“Š Success Rate: {analysis['summary']['success_rate']:.1f}%
ðŸ“Š Validity Rate: {analysis['summary']['validity_rate']:.1f}%

Performance Metrics:
-------------------
â° Total Time: {analysis['performance']['total_time_seconds']:.2f} seconds ({analysis['performance']['total_time_minutes']:.2f} minutes)
ðŸš€ Speed: {analysis['performance']['emails_per_second']:.2f} emails/second
âš¡ Per Email: {analysis['performance']['seconds_per_email']:.3f} seconds/email
ðŸ“ˆ Average Rate: {analysis['performance']['avg_rate']:.2f} emails/sec
ðŸ“‰ Min Rate: {analysis['performance']['min_rate']:.2f} emails/sec
ðŸ“ˆ Max Rate: {analysis['performance']['max_rate']:.2f} emails/sec

Domain Analysis:
---------------
ðŸŒ Unique Domains: {analysis['domains']['unique_domains']:,}

Top 10 Domains:
"""
    
    for i, (domain, stats) in enumerate(analysis['domains']['top_domains'], 1):
        validity_rate = (stats['valid'] / stats['total'] * 100) if stats['total'] > 0 else 0
        report += f"{i:2d}. {domain:<20} - {stats['total']:4d} emails ({validity_rate:5.1f}% valid)\n"
    
    report += f"""

Competitor Comparison:
---------------------
ðŸ¥‡ Mailgun:        2-8 minutes for 5K emails
ðŸ¥ˆ Hunter.io:      4-12 minutes for 5K emails  
ðŸ¥‰ ZeroBounce:     8-17 minutes for 5K emails
ðŸ† Your Validator: {analysis['performance']['total_time_minutes']:.1f} minutes for {analysis['summary']['processed_emails']:,} emails

Performance Rating:
------------------
"""
    
    time_minutes = analysis['performance']['total_time_minutes']
    if time_minutes <= 2:
        rating = "ðŸ† EXCELLENT - Faster than Mailgun!"
    elif time_minutes <= 8:
        rating = "ðŸ¥‡ GREAT - Competitive with top validators!"
    elif time_minutes <= 17:
        rating = "ðŸ¥ˆ GOOD - Matches ZeroBounce speed"
    else:
        rating = "ðŸ¥‰ NEEDS IMPROVEMENT - Slower than competitors"
    
    report += f"{rating}\n"
    
    report += f"""
Technical Details:
-----------------
ðŸ“Š Progress Updates: {analysis['progress_updates']:,}
ðŸ”„ Real-time Streaming: âœ… Working
âš¡ Parallel Processing: âœ… Active (20 threads)
ðŸ’¾ DNS Caching: âœ… Active
ðŸ“¦ Batch DB Writes: âœ… Active (20 per batch)

================================================================================
"""
    
    return report

def main():
    """Main test function."""
    print("ðŸ§ª EMAIL VALIDATOR PERFORMANCE TEST")
    print("=" * 50)
    
    # Load emails
    emails = load_emails_from_csv('real_emails_test_1000.csv')
    if not emails:
        print("âŒ No emails loaded. Exiting.")
        return
    
    print(f"ðŸ“§ Loaded {len(emails)} emails for testing")
    
    # Test Advanced mode
    print(f"\nðŸ”¬ Testing ADVANCED mode...")
    test_data = test_batch_validation(emails, mode='advanced')
    
    if test_data:
        # Analyze results
        analysis = analyze_results(test_data, emails)
        
        # Generate report
        report = generate_report(analysis, 'advanced')
        
        # Print report
        print(report)
        
        # Save report to file
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_filename = f'performance_report_{timestamp}.txt'
        
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ðŸ“„ Report saved to: {report_filename}")
        
        # Save raw data
        data_filename = f'performance_data_{timestamp}.json'
        with open(data_filename, 'w', encoding='utf-8') as f:
            json.dump({
                'test_data': test_data,
                'analysis': analysis,
                'emails_count': len(emails)
            }, f, indent=2)
        
        print(f"ðŸ“Š Raw data saved to: {data_filename}")
        
    else:
        print("âŒ Test failed. Make sure the backend is running on localhost:5000")

if __name__ == "__main__":
    main()